{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Multimodal_Audio_Emotion_Classification.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPtCG0Hb0zh0p0olsuCBV82"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S0r7hemFT8M1","executionInfo":{"status":"ok","timestamp":1634429976379,"user_tz":-540,"elapsed":24107,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"bb404c7c-df70-4099-e54a-cc549e689548"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"KVp626MlUNlS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634430015440,"user_tz":-540,"elapsed":39065,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"0d662463-1d48-49d1-e719-44cc396e8be3"},"source":["#필요한 모듈 설치하기\n","!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","!pip install torch\n","!pip install sklearn\n","!pip install pandas\n","!pip install numpy\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n","!pip install speechrecognition"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mxnet\n","  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n","\u001b[K     |████████████████████████████████| 46.9 MB 92.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.24)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595736 sha256=39d4d7732382a992cd9bc0c5d002adc2785b006071506c4c4305d47c1c9ff13a\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 4.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 83.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 66.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.3.0)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.46 tokenizers-0.8.1rc1 transformers-3.0.2\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-7dvqbvu8\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-7dvqbvu8\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.1.2-py3-none-any.whl size=12771 sha256=0e6146ab060c5260f6149b2ee0d52a05cfe788ba2cfbef59063f2647392286e4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-xt8m0q67/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n","Successfully built kobert\n","Installing collected packages: kobert\n","Successfully installed kobert-0.1.2\n","Collecting speechrecognition\n","  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n","\u001b[K     |████████████████████████████████| 32.8 MB 65 kB/s \n","\u001b[?25hInstalling collected packages: speechrecognition\n","Successfully installed speechrecognition-3.8.1\n"]}]},{"cell_type":"code","metadata":{"id":"DZaUWdDKUmdD"},"source":["# 기본 라이브러리 불러오기\n","import pandas as pd\n","import numpy as np\n","import os\n","import sys\n","\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","import librosa\n","import librosa.display\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# 경고메세지 숨기기\n","import warnings\n","if not sys.warnoptions:\n","    warnings.simplefilter(\"ignore\")\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","import gluonnlp as nlp\n","from tqdm import tqdm, tqdm_notebook\n","import pandas as pd\n","import numpy as np\n","\n","#kobert라이브러리에서 많이 쓰이는 함수 불러오기\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","#transformers에서 하이퍼파라미터 세팅\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","import pickle\n","\n","import speech_recognition as sr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JrJ60lzVU3rB"},"source":["#GPU 사용(권장)\n","device = torch.device(\"cuda:0\")\n","#CPU 사용\n","#device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"29OLcJ3SbXBZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVx1X3yxeotp"},"source":["음성 및 텍스트 데이터 준비"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6in_yPWAbXGW","executionInfo":{"status":"ok","timestamp":1634431640944,"user_tz":-540,"elapsed":1351,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"b6808e59-5c6e-4bfa-99ad-46fffb42ac8f"},"source":["#감성대화정보 엑셀로 불러오기\n","data_pre = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/감성대화/감성대화말뭉치_table.xlsx')\n","\n","# 감정데이터중에 필요없는 카테고리('당황') 제거해주기\n","\n","data_sub = data_pre.loc[(data_pre['감정_대분류'] == \"기쁨\") | (data_pre['감정_소분류'] == \"안달하는\") | (data_pre['감정_소분류'] == \"성가신\") | (data_pre['감정_소분류'] == \"툴툴대는\") | (data_pre['감정_소분류'] == \"방어적인\") | (data_pre['감정_소분류'] == \"혐오스러운\")\n"," | (data_pre['감정_소분류'] == \"비통한\") | (data_pre['감정_소분류'] == \"슬픔\") | (data_pre['감정_소분류'] == \"우울한\") | (data_pre['감정_소분류'] == \"실망한\") | (data_pre['감정_소분류'] == \"후회되는\") | (data_pre['감정_소분류'] == \"눈물이 나는\")\n"," | (data_pre['감정_소분류'] == \"걱정스러운\") | (data_pre['감정_소분류'] == \"조심스러운\") | (data_pre['감정_소분류'] == \"초조한\") | (data_pre['감정_소분류'] == \"두려운\") | (data_pre['감정_소분류'] == \"스트레스 받는\")\n"," | (data_pre['감정_소분류'] == \"고립된\") | (data_pre['감정_소분류'] == \"염세적인\") | (data_pre['감정_소분류'] == \"상처\") \n"," ]\n","# 음성이 있고 및 라벨에 맞는 데이터 개수 확인하기\n","len(data_sub)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2428"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"eyvgCgp67gGv","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1634431640945,"user_tz":-540,"elapsed":7,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"e6cd108d-ef25-48be-ecf2-3709508e30e6"},"source":["# 감정데이터 정수형(수치)로 바꿔주기 (정수 인코딩)\n","data_sub = data_sub.copy()\n","data_sub.loc[(data_sub['감정_소분류'] == \"안달하는\") | (data_sub['감정_소분류'] == \"성가신\") | (data_sub['감정_소분류'] == \"툴툴대는\") | (data_sub['감정_소분류'] == \"방어적인\") | (data_sub['감정_소분류'] == \"혐오스러운\"), 'Emotion'] = '분노'  #분노\n","data_sub.loc[(data_sub['감정_소분류'] == \"비통한\") | (data_sub['감정_소분류'] == \"슬픔\") | (data_sub['감정_소분류'] == \"우울한\") | (data_sub['감정_소분류'] == \"실망한\") | (data_sub['감정_소분류'] == \"후회되는\") | (data_sub['감정_소분류'] == \"눈물이 나는\"), 'Emotion'] = '우울'  #우울 \n","data_sub.loc[(data_sub['감정_소분류'] == \"걱정스러운\") | (data_sub['감정_소분류'] == \"조심스러운\") | (data_sub['감정_소분류'] == \"초조한\") | (data_sub['감정_소분류'] == \"두려운\") | (data_sub['감정_소분류'] == \"스트레스 받는\"), 'Emotion'] = '불안'  #불안 \n","data_sub.loc[(data_sub['감정_소분류'] == \"고립된\") | (data_sub['감정_소분류'] == \"염세적인\") | (data_sub['감정_소분류'] == \"상처\")  , 'Emotion'] = '자살'  #자살 \n","data_sub.loc[(data_sub['감정_대분류'] == \"기쁨\"), 'Emotion'] = '기쁨' #기쁨\n","\n","\n","# 음성데이터 라벨 및 경로데이터만 뽑아오기\n","data_path = data_sub.loc[:,['Emotion','NO.', '사람문장1']]\n","data_path.columns = ['Emotions','Path', 'Text']\n","\n","# 음성데이터 경로수정해주기(압축푼 폴더로 경로수정)\n","data_path['Path'] = '/content/drive/MyDrive/Colab Notebooks/감성대화/원천데이터/감성대화말뭉치AI데이터_Wave_남자성우_5000/'+data_path['Path']+'.wav'\n","\n","data_path.head(5)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotions</th>\n","      <th>Path</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>84</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","      <td>오늘 반장 선거에서 내가 반장이 됐어! 친구들이 날 믿어줘서 너무 고맙다.</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","      <td>오늘 시험에 친구가 알려준 문제가 나왔어. 결과가 좋아서 기쁘다.</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","      <td>오늘 대학 합격 통지를 받았어. 엄마가 너무 기뻐하는데 나는 눈물이 났어.</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","      <td>오늘 졸업식인데 선생님께서 아프셔서 오지 못하셨어. 그동안 감사하다는 말도 못했는데.</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","      <td>나 올림피아드에서 금상 받았어! 그동안 고생이 헛되지 않아서 너무 기뻐.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotions  ...                                             Text\n","84       기쁨  ...        오늘 반장 선거에서 내가 반장이 됐어! 친구들이 날 믿어줘서 너무 고맙다.\n","85       기쁨  ...             오늘 시험에 친구가 알려준 문제가 나왔어. 결과가 좋아서 기쁘다.\n","86       기쁨  ...        오늘 대학 합격 통지를 받았어. 엄마가 너무 기뻐하는데 나는 눈물이 났어.\n","87       기쁨  ...  오늘 졸업식인데 선생님께서 아프셔서 오지 못하셨어. 그동안 감사하다는 말도 못했는데.\n","88       기쁨  ...         나 올림피아드에서 금상 받았어! 그동안 고생이 헛되지 않아서 너무 기뻐.\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"fdK-DoCNIpCD"},"source":["# 음성데이터를 waveplot, spectrogram 이미지로 표현\n","\n","def create_waveplot(data, sr, e):\n","    plt.figure(figsize=(10, 3))\n","    plt.title('Waveplot for audio with {} emotion'.format(e), size=15)\n","    librosa.display.waveplot(data, sr=sr)\n","    plt.show()\n","\n","def create_spectrogram(data, sr, e):\n","    # stft 함수는 음성을 시간기반에서 주파수기반으로 변환함\n","    X = librosa.stft(data)\n","    Xdb = librosa.amplitude_to_db(abs(X))\n","    plt.figure(figsize=(12, 3))\n","    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n","    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n","    plt.colorbar()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zpVO8FbwK0Wp"},"source":["# 음성데이터 argumentation을 통해서 데이터 수 늘리기 및 오버피팅 방지\n","def noise(data):\n","    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n","    data = data + noise_amp*np.random.normal(size=data.shape[0])\n","    return data\n","\n","def stretch(data, rate=0.8):\n","    return librosa.effects.time_stretch(data, rate)\n","\n","def shift(data):\n","    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n","    return np.roll(data, shift_range)\n","\n","def pitch(data, sampling_rate, pitch_factor=0.7):\n","    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n","\n","# 예시\n","path = np.array(data_path.Path)[1]\n","data, sample_rate = librosa.load(path)\n","\n","# 음성의 특성추출하는 함수 ( MFCC, MEL, RMSV)\n","\n","def extract_features(data):\n","\n","    result = np.array([])\n","\n","    # MFCC\n","    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n","    result = np.hstack((result, mfcc)) # stacking horizontally\n","\n","    # Root Mean Square Value\n","#    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n","#    result = np.hstack((result, rms)) # stacking horizontally\n","\n","    # MelSpectogram\n","    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n","    result = np.hstack((result, mel)) # stacking horizontally\n","    \n","    return result\n","\n","# 음성의 특성을 추출한 데이터를 축적하는 함수 (Argumentation된 데이터도 같이)\n","def get_features(path):\n","    # duration과 offset은 각 오디오 파일의 시작과 끝에서 오디오가 없는 것을 처리\n","    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n","    \n","    # 원래데이터\n","    res1 = extract_features(data)\n","    result = np.array(res1)\n","    # 노이즈가 추가된 데이터\n","    noise_data = noise(data)\n","    res2 = extract_features(noise_data)\n","    result = np.vstack((result, res2)) # 병렬적으로 추가\n","\n","    # 피칭및 스트레칭된 데이터\n","    new_data = stretch(data)\n","    data_stretch_pitch = pitch(new_data, sample_rate)\n","    res3 = extract_features(data_stretch_pitch)\n","    result = np.vstack((result, res3)) # 병렬적으로 추가\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKeXTWIsK2E4"},"source":["# X, Y, Z = [], [], []\n","# for path, emotion, text in zip(data_path.Path, data_path.Emotions, data_path.Text):\n","#     feature = get_features(path)\n","#     for ele in feature:\n","#         X.append(ele)\n","#         # 2개의 augmentation이 존재하므로 총 한개의 음성데이터가 3개의 음성데이터가 됨\n","#         Y.append(emotion)\n","#         Z.append(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_1K_zVf6cKC"},"source":["Features = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ai/features3.csv')\n","# Features = pd.DataFrame(X)\n","# Features['labels'] = Y\n","# Features['text'] = Z\n","# Features.to_csv('features2.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUPZwZCwD6yh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634431822359,"user_tz":-540,"elapsed":5,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"31c8a189-3e0a-418c-e345-82da8f83b28e"},"source":["X = Features.iloc[: ,:-2].values  # Audio\n","Y = Features['labels'].values\n","Z = Features['text'].values  # Text "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['기쁨', '기쁨', '기쁨', ..., '기쁨', '기쁨', '기쁨'], dtype=object)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"xtJVVyW8VuHx"},"source":["le = LabelEncoder()\n","le = le.fit(Y)\n","Y = le.transform(Y)\n","# with open('/content/drive/MyDrive/Colab Notebooks/ai/label_encoder.pkl','wb') as f:\n","#   pickle.dump(le, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"228PNeaQVttR","executionInfo":{"status":"ok","timestamp":1634426024041,"user_tz":-540,"elapsed":5,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"d97562bf-d2e6-4059-83f3-7098afb55ff0"},"source":["# 훈련데이터, 테스트데이터 분리 및 개수 확인\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n","z_train, z_test, _, _ = train_test_split(Z, Y, random_state=0)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape, z_train.shape, z_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((5463, 148), (5463,), (1821, 148), (1821,), (5463,), (1821,))"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"ZKxENnmlkdRE"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61O5jJO2WWKm","executionInfo":{"status":"ok","timestamp":1634426025800,"user_tz":-540,"elapsed":7,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"ffcf88fd-f55d-489b-b845-5ba74e06869f"},"source":["# 음성 데이터 스케일 조정\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape\n","# with open('/content/drive/MyDrive/Colab Notebooks/ai/scaler.pkl','wb') as f:\n","#   pickle.dump(scaler, f)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((5463, 148), (5463,), (1821, 148), (1821,))"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mgj-XD70XoAG","executionInfo":{"status":"ok","timestamp":1634426026475,"user_tz":-540,"elapsed":7,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"e7e3d30d-d220-4511-8216-2207d274cb51"},"source":["# 음성 데이터의 차원 모델에 맞게 통일 \n","x_train = np.expand_dims(x_train, axis=2)\n","x_test = np.expand_dims(x_test, axis=2)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((5463, 148, 1), (5463,), (1821, 148, 1), (1821,))"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"vOf7-IPfWWNU"},"source":["x_train = torch.tensor(x_train, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.int64)\n","x_test = torch.tensor(x_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.int64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSAc_2hpxH5D"},"source":["audio_train_ds = TensorDataset(x_train, y_train)\n","audio_test_ds = TensorDataset(x_test, y_test)\n","audio_train_dataloader = torch.utils.data.DataLoader(audio_train_ds, batch_size=64)\n","audio_test_dataloader = torch.utils.data.DataLoader(audio_test_ds, batch_size=64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GgbJEjTSZECd"},"source":["# 텍스트 데이터 BERT 모델에 들어가기 위한 dataset을 만들어주는 클래스\n","class BERTDataset(Dataset):\n","    def __init__(self, data, label, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i]) for i in data]\n","        self.labels = [np.int32(i) for i in label]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SYuLH7GZVdq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634426129578,"user_tz":-540,"elapsed":28877,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"a6af34f5-d4c8-4f25-d4ff-6969043426f9"},"source":["# # BERT 모델, Vocabulary 불러오기\n","bertmodel, vocab = get_pytorch_kobert_model()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[██████████████████████████████████████████████████]\n","using cached model\n"]}]},{"cell_type":"code","metadata":{"id":"lXFEy-8yv2Bw"},"source":["# with open('/content/drive/MyDrive/Colab Notebooks/ai/kobert_data.pkl', 'wb') as f:\n","#   bertmodel, vocab = get_pytorch_kobert_model()\n","#   tokenizer = get_tokenizer()\n","#   pickle.dump([bertmodel, vocab, tokenizer],f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-P_sZU7Ox7Eu"},"source":["with open('/content/drive/MyDrive/Colab Notebooks/ai/kobert_data.pkl', 'rb') as f:\n","  bertmodel, vocab, _= pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JmhBH0jp8oVw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634426359554,"user_tz":-540,"elapsed":547,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"a818fbf9-1cc0-40ae-b26e-ee3e3fcc151f"},"source":["# #문장을 토크나이저를 통해서 토큰으로 변환(토큰화)\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","metadata":{"id":"7Tw3QaA18oYP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634426161545,"user_tz":-540,"elapsed":713,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"0656f3f0-99af-465e-a588-c260ef58457e"},"source":["# 데이터셋 BERT에 맞게 적용\n","max_len = 50\n","text_train_ds = BERTDataset(z_train, y_train, tok, max_len, True, False)\n","text_test_ds = BERTDataset(z_test, y_test, tok, max_len, True, False)\n","#bert모델에 넣기위해 torch형식으로 변환\n","text_train_dataloader = torch.utils.data.DataLoader(text_train_ds, batch_size=64, num_workers=5)\n","text_test_dataloader = torch.utils.data.DataLoader(text_test_ds, batch_size=64, num_workers=5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","metadata":{"id":"UrnKTEUpWfwW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mCSHnQJvyB8Y"},"source":["모델 설계 https://discuss.pytorch.org/t/combining-trained-models-in-pytorch/28383/2"]},{"cell_type":"code","metadata":{"id":"lIwWPAlsIjtR"},"source":["# 파라미터 세팅 ( 문장길이, 모델배치수,에폭수 ...)\n","max_len = 50\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 10\n","learning_rate =  3e-5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zku7ONsyyXlJ"},"source":["1. 음성모델"]},{"cell_type":"code","metadata":{"id":"zzj_K4O_yafE"},"source":["# 음성 모델 만들기\n","\n","class AudioClassifier(nn.Module):\n","    def __init__(self):\n","        super(AudioClassifier, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=x_train.shape[1], out_channels=256, kernel_size=1, stride=1,padding='same')\n","        self.max_pool1 = nn.MaxPool1d(5, stride=2, padding = 2)\n","\n","        self.conv2 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=5, stride=1, padding='same')\n","        self.max_pool2 = nn.MaxPool1d(5, stride=2, padding = 2)\n","\n","        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=5, stride=1, padding='same')\n","        self.max_pool3 = nn.MaxPool1d(5, stride=2, padding = 2)\n","        self.dropout1 = nn.Dropout(0.2)\n","        \n","        self.conv4 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=5, stride=1, padding='same')\n","        self.max_pool4 = nn.MaxPool1d(5, stride=2, padding = 2)\n","        \n","        self.fc1 = nn.Linear(64, 32)\n","        self.dropout2 = nn.Dropout(0.6)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.max_pool1(x)\n","\n","        x = F.relu(self.conv2(x))\n","        x = self.max_pool2(x)\n","\n","        x = F.relu(self.conv3(x))\n","        x = self.max_pool3(x)\n","        x = self.dropout1(x)\n","\n","        x = F.relu(self.conv4(x))\n","        x = self.max_pool4(x)\n","\n","        x = torch.flatten(x,1)\n","\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout2(x)\n","        \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpylE0_gWxHp"},"source":["model1 = AudioClassifier().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qfm_gwXKyZTE"},"source":["2. 텍스트모델"]},{"cell_type":"code","metadata":{"id":"nR0hDEA2Viwt"},"source":["# KoBERT 학습모델 만들기\n","class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=32,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yy6zmnp2gAjQ"},"source":["#BERT 모델 불러오기\n","model2 = BERTClassifier(bertmodel,  dr_rate=0.6).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvjU1Ft-yxB2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MB_Bmyoky1Wx"},"source":["멀티모달 모델"]},{"cell_type":"code","metadata":{"id":"e39cfR4jy0kG"},"source":["# 멀티모달 모델 만들기\n","\n","class MultimodalClassifier(nn.Module):\n","    def __init__(self, audioModel, textModel):\n","        super(MultimodalClassifier, self).__init__()\n","        self.audioModel = audioModel\n","        self.textModel = textModel\n","\n","        self.fc1 = nn.Linear(64,32)\n","        self.dropout1 = nn.Dropout(0.2)\n","\n","        self.fc2 = nn.Linear(32, 5)\n","\n","    def forward(self, x1, token_ids, valid_length, segment_ids):\n","        x1 = self.audioModel(x1)\n","        x2 = self.textModel(token_ids, valid_length, segment_ids)\n","        x = torch.cat((x1,x2), 1)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout1(x)\n","        \n","        x = F.relu(self.fc2(x))\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rJmOyWOy0oV"},"source":["# model3 = MultimodalClassifier(model1, model2).to(device)\n","model3 = torch.load('/content/drive/MyDrive/Colab Notebooks/ai/multimodal_emotion_classification.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"obPAvYSo0zGf"},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model3.parameters(), lr=0.0001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":504},"id":"WhCyJULscqyQ","executionInfo":{"status":"error","timestamp":1634396842783,"user_tz":-540,"elapsed":2971,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"6dd30be5-c71b-42ea-b798-d55367640142"},"source":["for epoch in range(num_epochs):\n","  cost, total, correct = 0,0,0\n","  for (i, (X, Y)), (_, (token_ids, valid_length, segment_ids, _)) in zip(enumerate(audio_train_dataloader), enumerate(text_train_dataloader)):\n","    optimizer.zero_grad()\n","    X, token_ids, valid_length, segment_ids, Y = X.to(device), token_ids.to(device), valid_length.to(device), segment_ids.to(device), Y.to(device)\n","    outputs = model3(X,token_ids, valid_length, segment_ids)\n","    loss = criterion(outputs, Y)\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    cost += loss\n","    if i % 10 == 9:\n","      print(f'epoch: {epoch} | batch_id: {i} | loss: {loss.item()}') # 밑에 test로 수정\n","  for (i, (X, Y)), (_, (token_ids, valid_length, segment_ids, _)) in zip(enumerate(audio_test_dataloader), enumerate(text_test_dataloader)):\n","    X, token_ids, valid_length, segment_ids, Y = X.to(device), token_ids.to(device), valid_length.to(device), segment_ids.to(device), Y.to(device)\n","    outputs = model3(X,token_ids, valid_length, segment_ids)\n","    total += Y.size(0)\n","    correct += sum(torch.argmax(outputs, 1) == Y)\n","  avg_cost = cost / len(audio_train_dataloader)\n","  accuracy = 100*correct/total\n","\n","  print(f'\\nepoch: {epoch} | loss: {avg_cost}\\naccuracy: {accuracy}\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-2cb90e369702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ZaFBjZngRylG"},"source":["# # Empty CUDA\n","# import gc\n","# gc.collect()\n","# torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mi2oOhFt01n7"},"source":["# torch.save(model3,'/content/drive/MyDrive/Colab Notebooks/ai/multimodal_emotion_classification.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jImrMbcN01sj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WgdIwiMxL5RP","executionInfo":{"status":"ok","timestamp":1634396903444,"user_tz":-540,"elapsed":3523,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"9f0afc23-75a2-4c0b-e344-5eb892f60286"},"source":["y_pred = np.array([])\n","y_test = np.array([])\n","for (i, (X, Y)), (_, (token_ids, valid_length, segment_ids, _)) in zip(enumerate(audio_test_dataloader), enumerate(text_test_dataloader)):\n","  X, token_ids, valid_length, segment_ids, Y = X.to(device), token_ids.to(device), valid_length.to(device), segment_ids.to(device), Y.to(device)\n","  outputs = model3(X,token_ids, valid_length, segment_ids)\n","  y_pred = np.append(y_pred, np.array(torch.argmax(outputs,1).cpu()))\n","  y_test = np.append(y_test, np.array(Y.cpu()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","metadata":{"id":"tezjknrAWwjy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634396908945,"user_tz":-540,"elapsed":544,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"9f4b2a47-0231-4f5a-baea-571985a7a447"},"source":["print(classification_report(y_test, y_pred))  # class 한글로 뜨게"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.90      0.89       612\n","         1.0       0.89      0.85      0.87       340\n","         2.0       0.85      0.83      0.84       287\n","         3.0       0.85      0.83      0.84       359\n","         4.0       0.75      0.78      0.76       223\n","\n","    accuracy                           0.85      1821\n","   macro avg       0.84      0.84      0.84      1821\n","weighted avg       0.85      0.85      0.85      1821\n","\n"]}]},{"cell_type":"code","metadata":{"id":"wktGxGumZheT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8zDOusiZhhT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mCEUjrDGuBV2"},"source":["실제 데이터 모델 성능 테스트"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"krKkxO3Jn2qs","executionInfo":{"status":"ok","timestamp":1634430068243,"user_tz":-540,"elapsed":1401,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"b41a252d-3a6b-44df-f393-351d021b2498"},"source":["cd /content/drive/MyDrive/Colab Notebooks/ai/완성"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/ai/완성\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"821Miyghu9ly","executionInfo":{"status":"ok","timestamp":1634430078390,"user_tz":-540,"elapsed":4900,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"e1bf313d-8b66-42f3-b85e-fa5180756496"},"source":["#감성대화정보 엑셀로 불러오기\n","data_pre= pd.read_excel('/content/drive/MyDrive/Colab Notebooks/감성대화/감성대화말뭉치_table.xlsx')\n","\n","# 감정데이터중에 필요없는 카테고리('당황') 제거해주기\n","data_sub = data_pre.loc[(data_pre['감정_대분류'] == \"기쁨\") | (data_pre['감정_소분류'] == \"안달하는\") | (data_pre['감정_소분류'] == \"성가신\") | (data_pre['감정_소분류'] == \"툴툴대는\") | (data_pre['감정_소분류'] == \"방어적인\") | (data_pre['감정_소분류'] == \"혐오스러운\")\n"," | (data_pre['감정_소분류'] == \"비통한\") | (data_pre['감정_소분류'] == \"슬픔\") | (data_pre['감정_소분류'] == \"우울한\") | (data_pre['감정_소분류'] == \"실망한\") | (data_pre['감정_소분류'] == \"후회되는\") | (data_pre['감정_소분류'] == \"눈물이 나는\")\n"," | (data_pre['감정_소분류'] == \"걱정스러운\") | (data_pre['감정_소분류'] == \"조심스러운\") | (data_pre['감정_소분류'] == \"초조한\") | (data_pre['감정_소분류'] == \"두려운\") | (data_pre['감정_소분류'] == \"스트레스 받는\")\n"," | (data_pre['감정_소분류'] == \"고립된\") | (data_pre['감정_소분류'] == \"염세적인\") | (data_pre['감정_소분류'] == \"상처\") \n"," ]\n","\n","print(data_sub['감정_대분류'].value_counts())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["기쁨    827\n","슬픔    590\n","불안    379\n","분노    339\n","상처    167\n","당황    126\n","Name: 감정_대분류, dtype: int64\n"]}]},{"cell_type":"code","metadata":{"id":"F9O7L5sJy7IV"},"source":["# 감정데이터 정수형(수치)로 바꿔주기 (정수 인코딩)\n","data_sub = data_sub.copy()\n","data_sub.loc[(data_sub['감정_소분류'] == \"안달하는\") | (data_sub['감정_소분류'] == \"성가신\") | (data_sub['감정_소분류'] == \"툴툴대는\") | (data_sub['감정_소분류'] == \"방어적인\") | (data_sub['감정_소분류'] == \"혐오스러운\"), 'Emotion'] = '분노'  #분노\n","data_sub.loc[(data_sub['감정_소분류'] == \"비통한\") | (data_sub['감정_소분류'] == \"슬픔\") | (data_sub['감정_소분류'] == \"우울한\") | (data_sub['감정_소분류'] == \"실망한\") | (data_sub['감정_소분류'] == \"후회되는\") | (data_sub['감정_소분류'] == \"눈물이 나는\"), 'Emotion'] = '우울'  #우울 \n","data_sub.loc[(data_sub['감정_소분류'] == \"걱정스러운\") | (data_sub['감정_소분류'] == \"조심스러운\") | (data_sub['감정_소분류'] == \"초조한\") | (data_sub['감정_소분류'] == \"두려운\") | (data_sub['감정_소분류'] == \"스트레스 받는\"), 'Emotion'] = '불안'  #불안 \n","data_sub.loc[(data_sub['감정_소분류'] == \"고립된\") | (data_sub['감정_소분류'] == \"염세적인\") | (data_sub['감정_소분류'] == \"상처\")  , 'Emotion'] = '자살'  #자살 \n","data_sub.loc[(data_sub['감정_대분류'] == \"기쁨\"), 'Emotion'] = '기쁨' #기쁨"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"Hnzhq9fIvYf8","executionInfo":{"status":"ok","timestamp":1634430078392,"user_tz":-540,"elapsed":8,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"b32cf285-4bf6-459b-db3a-76df16bc1b63"},"source":["# 음성데이터 라벨 및 경로데이터만 뽑아오기\n","data_path = data_sub.loc[:,['Emotion','NO.']]\n","data_path.columns = ['Emotions','Path']\n","\n","# 음성데이터 경로수정해주기(압축푼 폴더로 경로수정)\n","data_path['Path'] = '/content/drive/MyDrive/Colab Notebooks/감성대화/원천데이터/감성대화말뭉치AI데이터_Wave_남자성우_5000/'+data_path['Path']+'.wav'\n","\n","data_path.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotions</th>\n","      <th>Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>84</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotions                                               Path\n","84       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","85       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","86       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","87       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","88       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","89       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","90       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","91       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","92       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","93       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ..."]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"W3k_vHGa4eiK","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1634430078392,"user_tz":-540,"elapsed":7,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"2ddb8b7a-b75c-4a2c-ed68-d9a7bf0f47ff"},"source":["data_path = data_path.sample(frac=1).reset_index(drop=True)  # shuffling하고 index reset\n","data_path"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotions</th>\n","      <th>Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>분노</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>자살</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2423</th>\n","      <td>불안</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>2424</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>2425</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>2426</th>\n","      <td>기쁨</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","    <tr>\n","      <th>2427</th>\n","      <td>자살</td>\n","      <td>/content/drive/MyDrive/Colab Notebooks/감성ᄃ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2428 rows × 2 columns</p>\n","</div>"],"text/plain":["     Emotions                                               Path\n","0          기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","1          분노  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","2          자살  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","3          기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","4          기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","...       ...                                                ...\n","2423       불안  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","2424       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","2425       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","2426       기쁨  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","2427       자살  /content/drive/MyDrive/Colab Notebooks/감성ᄃ...\n","\n","[2428 rows x 2 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"DkuQZ9P442Ba","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1634430084853,"user_tz":-540,"elapsed":809,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"764cac48-ca5b-4325-faac-21e003ead970"},"source":["target = data_path['Path'].iloc[1]\n","target\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Colab Notebooks/감성대화/원천데이터/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_002240.wav'"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"X8Z-ts5KyOqG"},"source":["r = sr.Recognizer()\n","harvard = sr.AudioFile(target)\n","with harvard as source:\n","  audio = r.record(source)\n","text = r.recognize_google(audio, language='ko-KR')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"CLglLFDMesA0","executionInfo":{"status":"ok","timestamp":1634430108019,"user_tz":-540,"elapsed":11,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"9bdf6d91-cae9-4112-fe58-02138b3aa88e"},"source":["text"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'자녀들이 손자를 봐 달라고 자꾸 조르네'"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"VVraJhSf1jOi"},"source":["# 음성의 특성추출하는 함수 ( MFCC, MEL, RMSV)\n","def extract_features(data):\n","\n","    result = np.array([])\n","\n","    # MFCC\n","    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n","    result = np.hstack((result, mfcc)) # stacking horizontally\n","\n","    # Root Mean Square Value\n","#    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n","#    result = np.hstack((result, rms)) # stacking horizontally\n","\n","    # MelSpectogram\n","    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n","    result = np.hstack((result, mel)) # stacking horizontally\n","    \n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNzBK-ns6TDd"},"source":["data, sample_rate = librosa.load(target, duration=2.5, offset=0.6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgdaHSiE1jUJ"},"source":["feature = np.array(extract_features(data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCUrJAFH1jWE"},"source":["x = feature.reshape(1,-1)\n","z = text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSG5Zrnd1jbS"},"source":["# # 음성 데이터 스케일 조정\n","with open('/content/drive/MyDrive/Colab Notebooks/ai/scaler.pkl','rb') as f:\n","  scaler = pickle.load(f)\n","x = scaler.transform(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N5Q4QS7U1iDX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634430151358,"user_tz":-540,"elapsed":489,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"9d65ce29-a6a3-41c5-8b22-be7bede8888e"},"source":["# 음성 데이터의 차원 모델에 맞게 통일 \n","x = np.expand_dims(x, axis=2)\n","x.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 148, 1)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r3yl_ONpX2C3","executionInfo":{"status":"ok","timestamp":1634430174015,"user_tz":-540,"elapsed":4267,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"f2dca8f9-3466-4eb5-9737-29a672a92e1d"},"source":["X = torch.tensor(x, dtype=torch.float32)\n","\n","#문장을 토크나이저를 통해서 토큰으로 변환(토큰화)\n","with open('/content/drive/MyDrive/Colab Notebooks/ai/kobert_data.pkl', 'rb') as f:\n","  bertmodel, vocab, _ = pickle.load(f)\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","metadata":{"id":"T7v1sRwP1iF0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634430175719,"user_tz":-540,"elapsed":15,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"09142580-deb7-48aa-9b1b-a99ac52717ee"},"source":["\n","transform = nlp.data.BERTSentenceTransform(\n","            tok, max_seq_length=50, pad=True, pair=False)\n","\n","Z = list(transform(z))\n","Z1, Z2, Z3 = torch.tensor(Z[0].reshape(1,-1)),torch.tensor(Z[1].reshape(1,-1)),torch.tensor(Z[2].reshape(1,-1))\n","\n","\n","X.shape, Z1.shape,Z2.shape,Z3.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 148, 1]),\n"," torch.Size([1, 50]),\n"," torch.Size([1, 1]),\n"," torch.Size([1, 50]))"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"9Rn1XYjcaTdC"},"source":["# 음성 모델 만들기\n","\n","class AudioClassifier(nn.Module):\n","    def __init__(self):\n","        super(AudioClassifier, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=x_train.shape[1], out_channels=256, kernel_size=1, stride=1,padding='same')\n","        self.max_pool1 = nn.MaxPool1d(5, stride=2, padding = 2)\n","\n","        self.conv2 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=5, stride=1, padding='same')\n","        self.max_pool2 = nn.MaxPool1d(5, stride=2, padding = 2)\n","\n","        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=5, stride=1, padding='same')\n","        self.max_pool3 = nn.MaxPool1d(5, stride=2, padding = 2)\n","        self.dropout1 = nn.Dropout(0.2)\n","        \n","        self.conv4 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=5, stride=1, padding='same')\n","        self.max_pool4 = nn.MaxPool1d(5, stride=2, padding = 2)\n","        \n","        self.fc1 = nn.Linear(64, 32)\n","        self.dropout2 = nn.Dropout(0.6)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.max_pool1(x)\n","\n","        x = F.relu(self.conv2(x))\n","        x = self.max_pool2(x)\n","\n","        x = F.relu(self.conv3(x))\n","        x = self.max_pool3(x)\n","        x = self.dropout1(x)\n","\n","        x = F.relu(self.conv4(x))\n","        x = self.max_pool4(x)\n","\n","        x = torch.flatten(x,1)\n","\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout2(x)\n","        \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3VKFotILaTdE"},"source":["# KoBERT 학습모델 만들기\n","class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=32,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SAK8Rzn-aOR1"},"source":["# 멀티모달 모델 만들기\n","\n","class MultimodalClassifier(nn.Module):\n","    def __init__(self, audioModel, textModel):\n","        super(MultimodalClassifier, self).__init__()\n","        self.audioModel = audioModel\n","        self.textModel = textModel\n","\n","        self.fc1 = nn.Linear(64,32)\n","        self.dropout1 = nn.Dropout(0.2)\n","\n","        self.fc2 = nn.Linear(32, 5)\n","\n","    def forward(self, x1, token_ids, valid_length, segment_ids):\n","        x1 = self.audioModel(x1)\n","        x2 = self.textModel(token_ids, valid_length, segment_ids)\n","        x = torch.cat((x1,x2), 1)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout1(x)\n","        \n","        x = F.relu(self.fc2(x))\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtLbN1mSfNP5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"efZm3ygG06TG"},"source":["model = torch.load('/content/drive/MyDrive/Colab Notebooks/ai/multimodal_emotion_classification.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zd1FEyRt06UU"},"source":["output = model(X.to(device), Z1.to(device), Z2.to(device),Z3.to(device))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ECqH_dHAmN-Z"},"source":["output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fz6Nztyy06Vq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634426633557,"user_tz":-540,"elapsed":406,"user":{"displayName":"조성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06387803399425222832"}},"outputId":"966ee0dc-5822-44f7-e022-5aa05d00cdd0"},"source":["le.inverse_transform([torch.argmax(output.cpu())])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['우울'], dtype=object)"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"kYZ3NVUn06XB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eYIaX4RH06bG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbX9E2bV06dJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DWXzDwh206ed"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQUaBrm106gU"},"source":[""],"execution_count":null,"outputs":[]}]}